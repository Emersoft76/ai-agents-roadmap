# 📊 Evaluation & Observability | Avaliação e Observabilidade

> Evaluating and monitoring AI agent performance is crucial for reliability, improvement, and debugging.  
> Avaliar e monitorar o desempenho de agentes de IA é essencial para confiabilidade, melhorias e depuração.

---

## 📏 Evaluation Metrics

| Metric (EN) | Métrica (PT)  | Description (EN/PT)                                       |
|-------------|----------------|-----------------------------------------------------------|
| Accuracy    | Acurácia       | Measures correctness / Mede a exatidão das respostas      |
| Coherence   | Coerência      | Evaluates logical flow / Avalia o encadeamento lógico     |
| Relevance   | Relevância     | Checks if output is on-topic / Verifica se é pertinente   |
| Factuality  | Factualidade   | Verifies truth / Verifica a veracidade                    |
| Efficiency  | Eficiência     | Measures response time / Mede tempo de resposta           |

---

## 🧪 Tools & Techniques

| Tool / Technique       | Description (EN)                 | Descrição (PT)                          |
|------------------------|----------------------------------|-----------------------------------------|
| Human feedback         | Ratings or comparisons           | Avaliações ou comparações humanas       |
| Model-based evaluators | Use another LLM to score/explain | Usa outro LLM para avaliar ou explicar  |
| Benchmarks             | e.g., AgentBench, HELM, MMLU     | Ex: AgentBench, HELM, MMLU              |
| Logging & tracing      | Log input/output chains          | Registro de entradas/saídas encadeadas  |
| Telemetry              | Usage metrics                    | Métricas de uso                         |

---

## 🔍 Observability Features

| Feature (EN)           | Recurso (PT)                |
|------------------------|-----------------------------|
| Input/output logging   | Registro de entrada/saída   |
| Trace visualization    | Visualização de execução    |
| Token counting         | Contagem de tokens          |
| Model diagnostics      | Diagnóstico do modelo       |
| Latency tracking       | Rastreamento de latência    |

---

## 🧠 Summary | Resumo

> Robust observability enables trust and accountability in AI agents. Evaluation methods ensure consistent quality and improvement.  
> Uma boa observabilidade permite confiança e responsabilidade nos agentes de IA. Métodos de avaliação garantem qualidade e melhorias contínuas.

---

⬅️ Back to [`multi-agents.md`](multi-agents.md)
